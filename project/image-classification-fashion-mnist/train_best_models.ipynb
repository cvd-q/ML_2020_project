{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from tb_imgs_utilities import image_grid, plot_to_image, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.python.keras.engine import data_adapter\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "N_CLASS = 10\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "cl = np.arange(N_CLASS).reshape((N_CLASS, 1))\n",
    "enc.fit(cl)\n",
    "log_dir = 'logs/InceptionResnet_best'  # './logs/'\n",
    "checkpoint_filepath = 'checkpoint_InceptionResnet_best/'  # './checkpoint/'\n",
    "\n",
    "# PREPARE DATA\n",
    "DATA_BASE_FOLDER = '/kaggle/input/ml-project-2020-dataset/'\n",
    "x_train = np.load(os.path.join(DATA_BASE_FOLDER, 'train.npy'))\n",
    "x_valid = np.load(os.path.join(DATA_BASE_FOLDER, 'validation.npy'))\n",
    "x_test = np.load(os.path.join(DATA_BASE_FOLDER, 'test.npy'))\n",
    "y_train = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'train.csv'))['class'].values\n",
    "y_valid = pd.read_csv(os.path.join(DATA_BASE_FOLDER, 'validation.csv'))['class'].values\n",
    "\n",
    "y_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28)  # reconstruct images\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], 28, 28)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28)\n",
    "x_train = tf.expand_dims(x_train, axis=-1)\n",
    "x_valid = tf.expand_dims(x_valid, axis=-1)\n",
    "x_test = tf.expand_dims(x_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_dataset import InceptionResNetV2Fashion, CMTensorBoardCallback\n",
    "#,conv2d_bn, inception_resnet_block\n",
    "\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training two models selected\n",
    "(training one model by step, since training requires much time......)\n",
    "(more 'clean' codes to reduce training time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The smaller model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = ' ' + 'small'\n",
    "print('HP ---> ', dir_name)\n",
    "file_writer = tf.summary.create_file_writer(log_dir + dir_name)\n",
    "tb_cm_callback = CMTensorBoardCallback(file_writer,\n",
    "                                        log_dir=(log_dir + dir_name))\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath + dir_name,\n",
    "                                                         save_weights_only=True,\n",
    "                                                         monitor='val_accuracy',\n",
    "                                                         mode='max',\n",
    "                                                         save_best_only=True)\n",
    "early_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='accuracy', min_delta=0, patience=6, verbose=1,\n",
    "    mode='max'\n",
    ")\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', factor=0.2, mode = 'max',\n",
    "                              patience=3, min_lr=0.0001, verbose=1)\n",
    "\n",
    "model = InceptionResNetV2Fashion((28, 28, 1), N_CLASS,\n",
    "                                 2,\n",
    "                                 0.5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric],\n",
    "              run_eagerly=False)\n",
    "\n",
    "# CREATE DATASET\n",
    "x_train_flip = tf.image.random_flip_left_right(x_train)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_flip, y_train))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "\n",
    "train_dataset = train_dataset.map(scale).cache().shuffle(10000).batch(BATCH_SIZE).prefetch(3)\n",
    "valid_dataset = valid_dataset.map(scale).batch(BATCH_SIZE*10) #scale function MANDATORY\n",
    "\n",
    "print('*************** START TRAINING *******************')\n",
    "model.fit(train_dataset,\n",
    "          validation_data=valid_dataset,\n",
    "          epochs=10,\n",
    "          callbacks=[tb_cm_callback, checkpoint_callback, early_callback, reduce_lr_callback],\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_writer = tf.summary.create_file_writer(log_dir + dir_name)\n",
    "# \n",
    "# # CMTensorBoardCallback codes\n",
    "# # Use the model to predict the values from the validation dataset.\n",
    "# test_pred_raw = model.predict(x_valid)  # for large input\n",
    "# # AUROC print\n",
    "# y_pred = np.squeeze(test_pred_raw)\n",
    "# y_ohe = np.squeeze(y_valid)\n",
    "# y_ohe = np.expand_dims(y_ohe, axis=1)\n",
    "# y_ohe = enc.transform(y_ohe).toarray()\n",
    "# r_sum = 0\n",
    "# for c in range(N_CLASS):\n",
    "#     try:\n",
    "#         r = roc_auc_score(y_ohe[:, c], y_pred[:, c])\n",
    "#         print('Label: ', y_labels[c], ', ', 'AUROC one vs rest = ', r)\n",
    "#         r_sum += r\n",
    "#     except ValueError:\n",
    "#         print('Label: ', y_labels[c], ', ', 'AUROC one vs rest = None!')\n",
    "# mean_auroc = r_sum / N_CLASS\n",
    "# print('MEAN AUROC: ', mean_auroc)\n",
    "# \n",
    "# test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "# # Calculate the confusion matrix.\n",
    "# cm = confusion_matrix(y_valid, test_pred)\n",
    "# # Log the confusion matrix as an image summary.\n",
    "# figure = plot_confusion_matrix(cm, y_labels)\n",
    "# cm_image = plot_to_image(figure)\n",
    "# # Log the confusion matrix as an image summary.\n",
    "# with file_writer.as_default():\n",
    "#     tf.summary.image(\"End training small model: Confusion Matrix\", cm_image,\n",
    "#                      description='Smaller InceptionResNetV2Fashion: initial_lr=0.001(ReduceLROnPlateau), Adam optimizer and drop_rate=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The bigger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_name = ' ' + 'big'\n",
    "# print('HP ---> ', dir_name)\n",
    "# file_writer = tf.summary.create_file_writer(log_dir + dir_name)\n",
    "# tb_cm_callback = CMTensorBoardCallback(file_writer,\n",
    "#                                         log_dir=(log_dir + dir_name))\n",
    "# checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath + dir_name,\n",
    "#                                                          save_weights_only=True,\n",
    "#                                                          monitor='val_accuracy',\n",
    "#                                                          mode='max',\n",
    "#                                                          save_best_only=True)\n",
    "# early_callback = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='accuracy', min_delta=0, patience=6, verbose=1,\n",
    "#     mode='max'\n",
    "# )\n",
    "# reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy', factor=0.2, mode = 'max',\n",
    "#                               patience=3, min_lr=0.0001, verbose=1)\n",
    "# \n",
    "# model = InceptionResNetV2Fashion((28, 28, 1), N_CLASS,\n",
    "#                                  1,\n",
    "#                                  0.5)\n",
    "# loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "# \n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "# \n",
    "# metric = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "# \n",
    "# model.compile(optimizer=optimizer, loss=loss, metrics=[metric],\n",
    "#               run_eagerly=False)\n",
    "# \n",
    "# # CREATE DATASET\n",
    "# x_train_flip = tf.image.random_flip_left_right(x_train)\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((x_train_flip, y_train))\n",
    "# valid_dataset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "# \n",
    "# train_dataset = train_dataset.map(scale).cache().shuffle(10000).batch(BATCH_SIZE).prefetch(2)\n",
    "# valid_dataset = valid_dataset.map(scale).batch(BATCH_SIZE*10) #scale function MANDATORY\n",
    "# \n",
    "# print('*************** START TRAINING *******************')\n",
    "# model.fit(train_dataset,\n",
    "#           validation_data=valid_dataset,\n",
    "#           epochs=10,\n",
    "#           callbacks=[tb_cm_callback, checkpoint_callback, early_callback, reduce_lr_callback],\n",
    "#           verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_writer = tf.summary.create_file_writer(log_dir + dir_name)\n",
    "# \n",
    "# # CMTensorBoardCallback codes\n",
    "# # Use the model to predict the values from the validation dataset.\n",
    "# test_pred_raw = model.predict(x_valid)  # for large input\n",
    "# # AUROC print\n",
    "# y_pred = np.squeeze(test_pred_raw)\n",
    "# y_ohe = np.squeeze(y_valid)\n",
    "# y_ohe = np.expand_dims(y_ohe, axis=1)\n",
    "# y_ohe = enc.transform(y_ohe).toarray()\n",
    "# r_sum = 0\n",
    "# for c in range(N_CLASS):\n",
    "#     try:\n",
    "#         r = roc_auc_score(y_ohe[:, c], y_pred[:, c])\n",
    "#         print('Label: ', y_labels[c], ', ', 'AUROC one vs rest = ', r)\n",
    "#         r_sum += r\n",
    "#     except ValueError:\n",
    "#         print('Label: ', y_labels[c], ', ', 'AUROC one vs rest = None!')\n",
    "# mean_auroc = r_sum / N_CLASS\n",
    "# print('MEAN AUROC: ', mean_auroc)\n",
    "# \n",
    "# test_pred = np.argmax(test_pred_raw, axis=1)\n",
    "# # Calculate the confusion matrix.\n",
    "# cm = confusion_matrix(y_valid, test_pred)\n",
    "# # Log the confusion matrix as an image summary.\n",
    "# figure = plot_confusion_matrix(cm, y_labels)\n",
    "# cm_image = plot_to_image(figure)\n",
    "# # Log the confusion matrix as an image summary.\n",
    "# with file_writer.as_default():\n",
    "#     tf.summary.image(\"End training big model: Confusion Matrix\", cm_image,\n",
    "#                      description='Bigger InceptionResNetV2Fashion: initial_lr=0.001(ReduceLROnPlateau), Adam optimizer and drop_rate=0.5)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 - Conda",
   "language": "python",
   "name": "python3-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
